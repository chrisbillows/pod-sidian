# 1 - WHAT DETAILS TO SAVE

# 1.1 - PODCAST DATA

For each podcast there will be a 'dictionary' stored in either JSON or probably SQLite

It could consist of any of: (e.g. podcastByFeedId)

 - ['id', 'podcastGuid', 'title', 'url', 'originalUrl', 'link', 'description', 'author', 'ownerName', 
 'image', 'artwork', 'lastUpdateTime', 'lastCrawlTime', 'lastParseTime', 'lastGoodHttpStatusTime', 
 'lastHttpStatus', 'contentType', 'itunesId', 'itunesType', 'generator', 'language', 'explicit', 'type', 
 'dead', 'chash', 'episodeCount', 'crawlErrors', 'parseErrors', 'categories', 'locked', 'imageUrlHash']

MVP YES
- title
- id (podcast/feed id)
- link (to double check it's what I want)

MVP MAYBE
- description
- author
- ownerName
- image/artwork (almost always the same)
- catergories (help search similar)

NEXT VERSION?
Alternatve retrieval (error catching)
- 'itunesId'
- 'url' 
- 'podcastGuid'


# 1.2 OUR GENERATED DATA

When the podcast is saved by the tracker, additional info should be captured:

- save date 
- feed validation check of some kind?

MVP OR NEXT VERSION
- need to offer download existing Episodes
- maybe batch episodes into ~20s in reverse chronology
- then accept multiple selections as a list after each 20 with a version to quit


2 - DOWNLOAD PROCESSING

- Cron job script runs every ~ hour
- Iterates over saved_pods dictionary
- Finds last episode we downloaded (??? best way) or save date, if new
- Checks for a more recent episode

3 - SAVING PROCESS METADATA

- On download of an episode, needs to save data from this e.g.
- save_datetime
- episode_id 

Next pass will check save_datetime against a new publish date.  

OR would it be better to check on episode_ids?  Store all the recent episode ids and just double check.

Might be more robust than effectively using milliseconds - do they ever change that? 
E.g if an episode needs correcting, and they delete and repost (although would a new ep id be allocated?)

Or consider 'newestItemPubdate'

Depends on how these fields flow into the API - be easier to check when we're actually downloading the data.
And we know enough for now.

*NEEDS experimentation*

4 - LOGGING

Somewhere in there, probably its own SQLite table?
